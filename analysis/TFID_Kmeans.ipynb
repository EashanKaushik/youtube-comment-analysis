{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries\n"
      ],
      "metadata": {
        "id": "syzktcRdD3GY"
      },
      "id": "syzktcRdD3GY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d2a07e3",
      "metadata": {
        "id": "8d2a07e3"
      },
      "outputs": [],
      "source": [
        "from read_data import combine_all, combine_category, read_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "850044b6",
      "metadata": {
        "id": "850044b6"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a52b830e",
      "metadata": {
        "id": "a52b830e"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "import string\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download NLTK \n"
      ],
      "metadata": {
        "id": "0QbOSRwUEDx3"
      },
      "id": "0QbOSRwUEDx3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34ae1b14",
      "metadata": {
        "id": "34ae1b14",
        "outputId": "fe4bafbc-06f5-452f-bc19-50fe46bb37a4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\risha\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\risha\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\risha\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     C:\\Users\\risha\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     C:\\Users\\risha\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping corpora\\omw-1.4.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read Data"
      ],
      "metadata": {
        "id": "1cAx4gNRERX4"
      },
      "id": "1cAx4gNRERX4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87c350ba",
      "metadata": {
        "id": "87c350ba"
      },
      "outputs": [],
      "source": [
        "data= read_data('0e3GPea1Tyg.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47723027",
      "metadata": {
        "id": "47723027",
        "outputId": "94dc2788-6b19-4303-f75b-00fb644a756d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Comment</th>\n",
              "      <th>Time</th>\n",
              "      <th>Likes</th>\n",
              "      <th>Reply Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MrBeast</td>\n",
              "      <td>Like I said in the video, subscribe if you hav...</td>\n",
              "      <td>2021-11-24T21:02:45Z</td>\n",
              "      <td>860124</td>\n",
              "      <td>411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Natanael De La Torre</td>\n",
              "      <td>IRL:squid game already IRL</td>\n",
              "      <td>2022-04-03T01:26:06Z</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Rexx2Byte</td>\n",
              "      <td>4:39 EYYYYYYY WASSUP NIGHT FOX</td>\n",
              "      <td>2022-04-03T01:19:41Z</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HK KING868</td>\n",
              "      <td>After reject Netflix</td>\n",
              "      <td>2022-04-03T01:06:44Z</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dragon Walker</td>\n",
              "      <td>some people just made the marbles game so conf...</td>\n",
              "      <td>2022-04-03T01:06:41Z</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Name                                            Comment  \\\n",
              "0               MrBeast  Like I said in the video, subscribe if you hav...   \n",
              "1  Natanael De La Torre                         IRL:squid game already IRL   \n",
              "2             Rexx2Byte                     4:39 EYYYYYYY WASSUP NIGHT FOX   \n",
              "3            HK KING868                               After reject Netflix   \n",
              "4         Dragon Walker  some people just made the marbles game so conf...   \n",
              "\n",
              "                   Time   Likes  Reply Count  \n",
              "0  2021-11-24T21:02:45Z  860124          411  \n",
              "1  2022-04-03T01:26:06Z       0            0  \n",
              "2  2022-04-03T01:19:41Z       1            0  \n",
              "3  2022-04-03T01:06:44Z       0            0  \n",
              "4  2022-04-03T01:06:41Z       1            0  "
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning"
      ],
      "metadata": {
        "id": "5L5REHSkEVIX"
      },
      "id": "5L5REHSkEVIX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3ca4a2d",
      "metadata": {
        "id": "a3ca4a2d"
      },
      "outputs": [],
      "source": [
        "#PreProcessing\n",
        "import string\n",
        "def get_wordnet_pos(pos_tag):\n",
        "    if pos_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif pos_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif pos_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif pos_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "    \n",
        "def clean_text(text):\n",
        "    # lower text\n",
        "    text = text.lower()\n",
        "    # tokenize text and remove puncutation\n",
        "    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n",
        "    # remove words that contain numbers\n",
        "    text = [word for word in text if not any(c.isdigit() for c in word)]\n",
        "    # remove stop words\n",
        "    stop = stopwords.words('english')\n",
        "    text = [x for x in text if x not in stop]\n",
        "    # remove empty tokens\n",
        "    text = [t for t in text if len(t) > 0]\n",
        "    # pos tag text\n",
        "    pos_tags = pos_tag(text)\n",
        "    # lemmatize text\n",
        "    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n",
        "    # remove words with only one letter\n",
        "    text = [t for t in text if len(t) > 1]\n",
        "    # join all\n",
        "    text = \" \".join(text)\n",
        "    return(text)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de99a9f7",
      "metadata": {
        "id": "de99a9f7"
      },
      "outputs": [],
      "source": [
        "data[\"Comment\"]=data[\"Comment\"].astype(str)\n",
        "data['Comment']= data['Comment'].apply( lambda x: clean_text(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "300d394d",
      "metadata": {
        "id": "300d394d"
      },
      "source": [
        "## Tf-ID and KMeans ++"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83740343",
      "metadata": {
        "id": "83740343"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "#creating the Tfid Object using sklearn \n",
        "vectorizer= TfidfVectorizer()\n",
        "X= vectorizer.fit_transform(data['Comment'].to_list())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26bcc772",
      "metadata": {
        "id": "26bcc772"
      },
      "outputs": [],
      "source": [
        "#KMeans\n",
        "km= KMeans(n_clusters= 3)\n",
        "labels=km.fit_predict(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c12fe61",
      "metadata": {
        "id": "5c12fe61"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "silhouette_score(X, labels)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.11"
    },
    "colab": {
      "name": "TFID_Kmeans.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}